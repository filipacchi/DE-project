{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8724b-7bef-4c19-8690-86205f69d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec88dd-058c-4be9-a280-05a00d97f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 1 # 1-4\n",
    "\n",
    "# Spark session build\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.130:7077\") \\\n",
    "        .appName(\"de16_sparky_loudness_linreg\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"300s\")\\\n",
    "        .config(\"spark.executor.instances\", num_cores)\\\n",
    "        .config(\"spark.executor.cores\",1)\\\n",
    "        .config(\"spark.cores.max\",num_cores)\\\n",
    "        .config(\"spark.default.parallelism\",num_cores)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://192.168.2.130:9000\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f2dda-d2fc-4a27-aa12-e40d8dc3a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of the DataFrame\n",
    "columns = StructType([\n",
    "    StructField('artist_name', StringType(), nullable=True),\n",
    "    StructField('danceability', DoubleType(), nullable=True),\n",
    "    StructField('duration', DoubleType(), nullable=True),\n",
    "    StructField('end_of_fade_in', DoubleType(), nullable=True),\n",
    "    StructField('energy', DoubleType(), nullable=True),\n",
    "    StructField('key', IntegerType(), nullable=True),\n",
    "    StructField('key_confidence', DoubleType(), nullable=True),\n",
    "    StructField('loudness', DoubleType(), nullable=True),\n",
    "    StructField('mode', IntegerType(), nullable=True),\n",
    "    StructField('mode_confidence', DoubleType(), nullable=True),\n",
    "    StructField('release', StringType(), nullable=True),\n",
    "    StructField('song_hotttnesss', DoubleType(), nullable=True),\n",
    "    StructField('song_id', StringType(), nullable=True),\n",
    "    StructField('start_of_fade_out', DoubleType(), nullable=True),\n",
    "    StructField('tempo', DoubleType(), nullable=True),\n",
    "    StructField('time_signature', IntegerType(), nullable=True),\n",
    "    StructField('time_signature_confidence', DoubleType(), nullable=True),\n",
    "    StructField('title', StringType(), nullable=True),\n",
    "    StructField('year', IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "\n",
    "# Read data from csv file on HDFS\n",
    "start_time1 = time.time()\n",
    "\n",
    "df = spark_session.read.csv(\"hdfs://192.168.2.130:9000/user/MillionSongSubset.csv\", header=False, schema=columns)\n",
    "for i in range(100-1): # Repeat a certain number of times to replicate the subset for different tests\n",
    "    df = df.union(spark_session.read.csv(\"hdfs://192.168.2.130:9000/user/MillionSongSubset.csv\", header=False, schema=columns))\n",
    "\n",
    "# Repartition and filter\n",
    "df = df.repartition(num_cores)\n",
    "filtered_df = df.filter(col(\"year\") != 0)\n",
    "\n",
    "print(f\"Data loading/filtering time: {time.time() - start_time1}\")\n",
    "\n",
    "# Check that the loaded data looks correct\n",
    "print(f'Partitions: {df.rdd.getNumPartitions()}')\n",
    "print(f'Count: {filtered_df.count()}')\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e33506-eb48-4d8f-94a9-d67c18555f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "start_time2 = time.time()\n",
    "\n",
    "# Assemble feature column\n",
    "assembler = VectorAssembler(inputCols=[\"year\"], outputCol=\"features\")\n",
    "assembled_df = assembler.transform(filtered_df)\n",
    "\n",
    "# Fit linear regression model to data\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"loudness\")\n",
    "model = lr.fit(assembled_df)\n",
    "\n",
    "print(f\"Model training time: {time.time() - start_time2}\")\n",
    "\n",
    "# Get coefficients of the fit regression\n",
    "coefficients = [model.coefficients[0], model.intercept]\n",
    "print(\"Coefficients of linear fit:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869d090-1a4e-45b5-885a-6a68348331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "start_time3 = time.time()\n",
    "\n",
    "# Collect data for scatter plot\n",
    "feature_data = np.array([row[0] for row in filtered_df.select(\"year\").take(10000)])\n",
    "target_data = np.array([row[0] for row in filtered_df.select(\"loudness\").take(10000)])\n",
    "plt.scatter(feature_data, target_data, 5, 'k')\n",
    "\n",
    "# Linear fit guideline\n",
    "x_values = np.linspace(min(feature_data), max(feature_data), 100)\n",
    "y_values = coefficients[0] * x_values + coefficients[1]\n",
    "plt.plot(x_values, y_values, color='red', label=\"Linear Regression\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Loudness\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plotting time: {time.time() - start_time3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142925d-110a-479b-b6fb-b021485526cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
